# ğŸš€ Quick Start: Adding Your 20 Research Papers

## âœ… What's Ready

âœ… **Folders created** - `research-papers/to-ingest/` and `research-papers/ingested/`  
âœ… **Bulk script built** - Auto-processes all files in folder  
âœ… **NPM command ready** - `npm run ingest-research`  
âœ… **Deduplication working** - Won't re-ingest same papers  
âœ… **Auto-metadata extraction** - Pulls info from filenames  

---

## ğŸ“ How to Add Your 20 Papers

### Step 1: Just Use Your PDFs!

**âœ… PDFs now work directly - no conversion needed!**

Just drop your `.pdf` files into the folder. The script automatically extracts text.

**Both formats supported:**
- âœ… `.pdf` - Auto-extracts text
- âœ… `.txt` - Plain text files

**Optional: Convert to TXT for cleaner results**

If PDF extraction doesn't work well, you can convert:

**Option A: Copy-Paste from PDF**
1. Open PDF, Cmd+A, Cmd+C
2. Paste into text editor
3. Save as `Author_Year_Title.txt`

**Option B: Use Online Tool**
- https://pdftotext.com

**Option C: Command Line**
```bash
pdftotext yourpaper.pdf Author_Year_Title.txt
```

---

### Step 2: Name Your Files

**Format:** `Author_Year_Title.pdf` or `Author_Year_Title.txt`

**Examples:**
```
Grant_2021_TeamDynamics.pdf          âœ… PDF
Cameron_2018_OrganizationalChange.pdf
Edmondson_1999_PsychologicalSafety.txt  âœ… TXT
Hackman_2002_LeadingTeams.pdf
```

**Don't worry about perfect formatting** - the script is smart:
- âœ… `Grant_2021_TeamDynamics.txt` â†’ Extracts all metadata
- âœ… `grant-2021.txt` â†’ Still finds year
- âœ… `teamdynamics_paper.txt` â†’ Uses filename as title

---

### Step 3: Drop Files in Folder

```bash
# Your 20 papers go here:
research-papers/to-ingest/
  â”œâ”€â”€ Paper1.txt
  â”œâ”€â”€ Paper2.txt
  â”œâ”€â”€ ...
  â””â”€â”€ Paper20.txt
```

---

### Step 4: Run One Command

```bash
npm run ingest-research
```

**That's it!** The script will:
1. Process all 20 files
2. Extract metadata
3. Create embeddings (~30-60s each)
4. Store in database
5. Move to `ingested/` folder

---

## ğŸ“Š What You'll See

```
ğŸ“š Bulk Research Ingestion

ğŸ“„ Found 20 file(s) to ingest

[1/20] Processing: Grant_2021_TeamDynamics.txt
  Title: Team Dynamics
  Authors: Grant
  Year: 2021
  Size: 12.3 KB
  âœ… Chunks created: 14
  âœ… Facts extracted: 0
  âœ… Moved to ingested/

[2/20] Processing: Cameron_2018_Change.txt
  ...

ğŸ“Š INGESTION SUMMARY
âœ… Successful: 20/20
âŒ Failed: 0/20
ğŸ“¦ Total chunks created: 187

âœ¨ Done!
```

---

## â±ï¸ Time & Cost

**For 20 papers:**
- **Time:** 10-20 minutes
- **Cost:** ~$0.40 (OpenAI embeddings)
- **Storage:** ~5-10 MB in database

**Per paper:**
- **Time:** 30-60 seconds
- **Cost:** $0.02
- **Chunks:** ~8-15 (depends on length)

---

## ğŸ§ª Test Your New Papers

After ingestion:

1. **Go to your app:** `http://localhost:3001/new`
2. **Generate a framework**
3. **Look for citations** - you should now see citations from your 20 papers!

Example:
```
ğŸ“š Research-Backed Insights          3 Sources

â‘  Grant (2021) - Team Dynamics              75%
â‘¡ Cameron (2018) - Organizational Change    68%
â‘¢ Edmondson (1999) - Psychological Safety   62%
```

---

## ğŸ¯ Pro Tips

### Clean Up PDFs First
Remove these sections to get better chunks:
- âŒ Table of contents
- âŒ References list
- âŒ Appendices
- âŒ Page headers/footers

Keep these:
- âœ… Abstract
- âœ… Introduction
- âœ… Findings
- âœ… Discussion
- âœ… Implications

### Better Metadata
If the auto-detection doesn't work well, manually edit the first few lines of your `.txt` file:

```txt
Title: The Human Side of Strategy
Authors: Grant, A., Cameron, K., Edmondson, A.
Year: 2021

[rest of content...]
```

The script will use these if present!

### Batch by Topic
Process similar papers together:
- First 10: Strategy papers
- Next 5: Culture papers
- Last 5: Team dynamics

This helps you test retrieval per topic.

---

## â“ Troubleshooting

### "No files found"
```bash
# Check you're in the right folder
ls research-papers/to-ingest/

# Should show your .txt files
```

### "File too short"
- Files must be > 100 characters
- Check file isn't empty or corrupt

### "Already exists"
- Paper was already ingested (deduplication working!)
- The script won't re-ingest duplicates
- If you want to re-ingest, delete from database first

### Failed to ingest X files
- Check console for specific error
- Failed files stay in `to-ingest/` for retry
- Fix the issue and run again

---

## ğŸ“š Current Corpus

After adding your 20 papers, you'll have:

**Papers:** 23 (Dalain + Nishii + Tosti + your 20)  
**Chunks:** ~200-250 total  
**Topics:** Diverse organizational science coverage  

---

## ğŸš€ What's Next

**After ingestion:**
1. âœ… Test retrieval - generate frameworks
2. âœ… Check citation diversity - different papers cited?
3. âœ… Adjust similarity threshold if needed (in `retrieval.ts`)
4. â³ Later: Build Web UI (Option 2) for ongoing management

**Future enhancements:**
- ğŸ“„ PDF upload (no manual conversion)
- ğŸ¨ Web UI with drag-and-drop
- ğŸ“Š Corpus management dashboard
- ğŸ” Search your research corpus
- ğŸ“ˆ Citation analytics

---

## ğŸ’ª You're Ready!

**When you have your 20 papers as `.txt` files:**

```bash
# 1. Drop them here
ls research-papers/to-ingest/
# Should show 20 files

# 2. Run ingestion
npm run ingest-research

# 3. Wait 10-20 minutes

# 4. Test in app!
```

**Let me know when you're ready to add them!** ğŸ‰

